\documentclass[a4paper, 12pt]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{geometry}

%Images
\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage{float}
\usepackage{subcaption} %  for subfigures environments 

% Booktabs
\usepackage{booktabs}

% Citation
\usepackage{csquotes}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage{cancel}

\usepackage[style=authoryear-comp,backend=biber]{biblatex}
%== use and define color ==%
\AtEveryCite{\color{blue}}
\addbibresource{references.bib}

% Configurations
\geometry{a4paper, margin=2.5cm}
\graphicspath{ {img/} }

% Macros utiles
\newcommand{\Normal}{\mathcal{N}}


% Titre du document
\title{Rapport de Projet : ANOVA Phylogénétique}
\author{Alizée Geffroy \and Louis Lacoste}
\date{\today}

\begin{document}

\maketitle

<<'init', include=FALSE>>=
    knitr::opts_chunk$set(echo = FALSE)
    require("knitr", quietly = TRUE)
    options(knitr.table.format = "latex")
@

<<'libraries', include=FALSE>>=
# "phytools", "phylotools"
necessary_packages <- c("ape", "here")
if (any(!(necessary_packages %in% installed.packages()))) {
    install.packages(necessary_packages)
}

# require(phytools)
# require(phylotools)
require(ape)
require(here)


source(here("R","utils.R"))
@

\newpage
\tableofcontents
\newpage

\section{Introduction}
\label{chap:intro}
% Introduction au projet, contexte, objectifs.
Ici contexte biologique, les données de \cite{gomez-mestrePhylogeneticAnalysesReveal2012}, les données de Paul et Mélina, etc.

Avec l'avènement des données massives de génomiques, transcriptomiques, protéomiques etc, il y a besoin de techniques statistiques robustes et passant à l'échelle permettant de mener à bien l'anal
Format des données : arbres phylogénétiques, données génétiques 
Arbres avec des petites branche: plusieurs individus par espèces avec chacun leurs données 
--> problème biologique 

Deux sujets différents écologie et transcriptomique mais une même méthode.

Pour données \cite{chenQuantitativeFrameworkCharacterizing2019} la figure~\ref{fig:arbre-chen2019} présente l'arbre phylogénétique :

\begin{figure}[!h]
    \centering
<<'plot-arbre-chen'>>=
    tree <- read.tree(here("R","chen2019.tree"))
    # Normalising tree edge length
    taille_tree <- diag(vcv(tree))[1]
    tree$edge.length <- tree$edge.length / taille_tree

    phytools::plotTree(tree, ftype="i")
@
    \caption{Arbre phylogénétique de \cite{chenQuantitativeFrameworkCharacterizing2019}}
    \label{fig:arbre-chen2019}
\end{figure}

Au vu de la forme des données étudiées, le projet s'est tourné vers une méthode d'ANOVA phylogénétique. 
Celle-ci sera d'abord décrite ainsi que d'autres outils mathématiques utilisés pour affiner la fiabilité du test dans une première partie. 
Viendra ensuite une partie de simulation destinée à comparer et étudier la méthode d'ANOVA phylogénétique sur des données d'arbre simulés. 
Enfin, on tester sur des données réelles. 
\newline
\newline
Un gène, comparer les moyennes d'expression d'un gène 
On connait les groupes
exemple individus malade/sain

Comparaison non pas sur individus malades/pas malades mais sur espèces différentes.
Pas possible de supposer iid, existe relations entre les individus et les groupes que l'on compare donc besoin de les prendre en compte.

Modele mixte la matrice des temps de divergences, BM simple sans erreurs, avec erreur (ajustement du ratio) avec OU...

\section{Méthodes}
\label{sec:methode}
% Revue de la littérature sur l'ANOVA phylogénétique.
Ici les rappels sur l'ANOVA, l'explication de l'ANOVA phylogénétique. La démonstration des limites de l'ANOVA phylogénétique par des simulations
Méthode: la partie maths anova, anova phylo, satterthwaite, 

\subsection{L'ANOVA}

L'ANOVA est un cas classique du modèle linéaire, nous utilison ici une forme matricielle.

Le principe de l'ANOVA est d'expliciter le lien entre une variable quantitative et une ou plusieurs variables qualitatives.

La forme matricielle usuelle de l'ANOVA à 1 facteur est la suivante :

\begin{equation}
    Y = X\beta + u \text{,} \quad u \sim \mathcal{N}_n(0, \sigma^2I_n)
    \label{eq:ANOVA}
\end{equation} 
\[
    \text{où} \quad \mathbf{Y} = \begin{bmatrix} Y_{11} \\\vdots\\ Y_1n_1 \\ Y_{21}\\ \vdots \\ Y_{2n_2} \end{bmatrix}\text{, } \mathbf{X} = \begin{bmatrix} \mathbf{1} & \mathbf{1_{n_1}} \end{bmatrix}=\begin{bmatrix} 1 & 1 \\ \vdots & \vdots\\1 & 1 \\ 1 & 0\\ \vdots & \vdots\\1 & 0 \end{bmatrix}\text{, }  \mathbf{\beta} = \begin{bmatrix} \beta_1 \\ \beta_2  \end{bmatrix} \text{, } n=n_1+n_2
\]

Les paramètres $(\beta_1, \beta_2, \sigma^2)$ de l'ANOVA sont estimables, grâce par exemple à la méthode du maximum de vraisemblance et ont des formules bien connues.

% ICI LES FORMULES: est ce que vraiment besoin des formules ? 

% LIMITES de l'ANOVA classique sur les données phylo

\subsection{L'ANOVA phylogénétique}
\label{subsec:anova-phylogenetique}
Dans la méthode d'ANOVA classique l'information portée par l'arbre phylogénétique n'est pas prise en compte. 
Le but de cette nouvelle méthode est de ne plus mettre cette information de côté et peut être obtenir de meilleurs résultats. 
En effet on peut imaginer, en considérant des traits évolutifs ou des séquences d'ADN, que des individus d'une même espèce ou bien d'espèces proche phylogénétiquement, pourraient avoir des valeurs proches.  
Il s'agira alors de modéliser l'arbre et les informations évolutives qu'ils contient de manière à l'incorporer. 
\newline
\newline
Comme décrit dans \cite{bastideModelesEvolutionCaracteres2022} l'évolution d'un trait nécessite de décrire ses fluctuations le long de l'arbre et ses branches. 
C'est pour cela que souvent cela est le résultat d'un processus stochastique à temps continu. 
Le processus classique est le mouvement brownien et c'est celui que nous avons utilisé. Il a cependant quelques limites qui ne font pas l'objet de ce rapport mais qui peuvent alors justifier le choix d'autres types de processus comme celui d'Ornstein-Uhlenbecks.
Le modèle de mouvement brownien va alors induire que les feuilles des arbres (nos observations) auront une distribution gausienne que l'on écrira sous la forme suivante:

\begin{equation}
    Y = X\beta + u \text{, } u \sim \mathcal{N}_n(0, \sigma^2_{phy}K)
    \label{eq:ANOVAphylo}
\end{equation} 


Les notations correspondent toujours à celles utilisées pour \eqref{eq:ANOVA}. La seule différence se trouvant dans la distribution de $u$ et la présence d'une matrice $K$.
Dans le cadre du mouvement brownien $K=(K_{i,j})_{1\leq i,j \leq n}=(t_{i,j})_{1\leq i,j \leq n}$ où $t_{i,j}$ représente le temps d’évolution commun aux espèces i et j. 
On peut voir un exemple utilisé dans les slides de cours \cite{bastideContinuousTraitEvolution}:
\begin{center}
    \includegraphics[width=0.7\textwidth]{matrix_K.png}
\end{center}

<<'plot-MB', warnings = FALSE, message = FALSE, fig.cap = "Exemple d'un arbre phylogénétique dont le trait est généré selon un Mouvement Brownien", out.width = "75%", fig.height = 3.5, fig.align = "center", fig.pos = "H">>=
source(here("simulations","mouvement_brownien.R"))
set.seed(12)
df <- generate_phylo_tree(5,100, 0.1)
df$id_branche <- as.factor(df$id_branche)

ggplot(df) +
    aes(x = time, y = traj, color = as.factor(id_branche))+
    geom_line() +
    # geom_vline(data = df[df$is_spec_time,], aes(xintercept = time, color = .data$id_branche), linetype = "dashed")+
    geom_point(data = df[df$is_spec_time,], aes(x = time, y = .data$traj), color = df[df$is_spec_time,]$id_branche, size = 4)+
    labs(color = "Espèce", x = "Temps", y = "Trait") +
    coord_fixed(ratio=0.75) +
    theme_minimal()
@

% Besoin de le dire qu'on fait une régression linéaire matrice structurée, 
% figure avec le Brownien sur l'arbre à reprendre dans le chapitre de livre

\subsection{ANOVA phylogénétique avec erreur de mesure}
Dans la section précedente, on a supposé que la seule source de variabilité provenait du mouvement brownien sur l'arbre.
On rajoute dans cette section une autre variabilité specifiée par $\sigma^2_{err}$ qui à partir de la formule précédente \eqref{eq:ANOVAphylo}, nous donne:
\begin{equation}
    Y = X\beta + u + \epsilon \text{, } \quad u \sim \mathcal{N}_n(0, \sigma^2_{phy}K) \text{,} \quad \epsilon \sim \mathcal{N}_n(0, \sigma^2_{err}I_n)
\label{eq:eq2err}
\end{equation} 
\begin{align}
    &\text{Alors } Y \sim \mathcal{N}_n(X\beta, \sigma^2_{phy}K + \sigma^2_{err}I_n) \notag\\
    &\text{On pose } \theta=(\sigma^2_{phy}, \sigma^2_{err}) \notag \\
    &\text{On définit pour la suite } Var_\theta(Y) = V(\theta) = \sigma^2_{phy}K + \sigma^2_{err}I_n
    \label{eq:VarTheta}
\end{align}

Comme décrit dans \cite{bastideModelesEvolutionCaracteres2022}, l'ajout de cette variance résiduelle dans notre modèle est crucial pour mieux représenter la complexité des données que nous traitons.
En effet, supposer que la seule source de variation entre les observations est le processus stochastique sur l'arbre phylogénétique (specifiée par $\sigma^2_{phy}K$) est souvent peu réaliste, surtout dans des contextes où les données sont hétérogènes ou comme on le verra plus tard, nous avons les données de plusieurs individus d'une même espèce.
C'est d'ailleurs pour ça qu'on peut parler de variation intraspécifique.
Cette hypothèse simplificatrice peut introduire des biais significatifs dans nos analyses, compromettant ainsi la validité des résultats obtenus.
En intégrant la variance résiduelle, qui capture l'effet indépendant de l'environnement sur chaque mesure, notre modèle devient plus flexible et mieux adapté pour tenir compte de la variabilité observée dans les données. 
Le modèle mixte phylogénétique résultant, combinant à la fois la variance phylogénétique et la variance résiduelle, nous permet de distinguer les effets héritables des effets non héritables, offrant ainsi une approche plus nuancée et réaliste de l'analyse comparative des données évolutives.
\newline
\newline
En posant $\lambda = \frac{\sigma^2_{phy}}{\sigma^2_{err}}$ et $E=u+\epsilon$, on peut obtenir une nouvelle forme pour $Y$
\begin{align}
    \label{eq:V_lambda}
    &Y = X\beta + E \text{, où } Var(E)=V(\theta)=\sigma^2_{phy}(K-\lambda I_n)=\sigma^2_{phy}V_\lambda \\
    &E \sim \mathcal{N}_n(0, V_\lambda) \notag
\end{align}

\subsection{Le test statistique}
Pour le test statistique d'ANOVA phylogénétique, on se met dans le cadre d'une ANOVA à un facteur et à 2 groupes. 
Chacun de ces groupes ayant une moyenne qui lui est propre. Ce peut être la moyenne de la valeur d'un trait génétique ou bien de la valeur de la fréquance d'une séquence ou allèle. 
On testera alors les hypothèses suivantes :
\[ H_0 : \beta_2 =0 \text{, les 2 groupes ont la même moyenne}\]
\[ H_1 : \beta_2\neq 0 \text{, les 2 groupes ont des moyennes différentes}\]

\cite{bastideContinuousTraitEvolution} nous donne une F-statistique pour la méthode d'ANOVA de cette forme \eqref{eq:V_lambda} et le test de Fisher précédent. 
\begin{equation}
    F=\frac{||\hat{Y} - \bar{Y}||^2_{V_\lambda^{-1}}(n-2)}{||Y - \hat{Y}||^2_{V_\lambda^{-1}}} \underset{\mathcal{H}_0}{\sim}\mathcal{F}\text{isher} (1, n-2)
\end{equation}

TODO: Rajouter def norme

\subsection{Approximation de Satterthwaite}

On va dans notre cas avoir $n-2$ degrés de liberté.
L'ANOVA, suppose souvent une homoscédasticité des variances entre les groupes ou les échantillons. Cela signifie que les variances des groupes sont égales.

Cependant, lorsque cette condition n'est pas satisfaite, l'approximation de Satterthwaite peut être utilisée pour tenir compte des variances inégales entre les groupes. Elle est particulièrement utile dans le cas des ANOVA à un facteur, mais peut également être appliquée à des ANOVA à plusieurs facteurs.

L'approximation de Satterthwaite ajuste les degrés de liberté pour tenir compte de ces différences dans les variances.
\newline
Cela permet d'obtenir des résultats plus fiables lorsque les conditions d'homoscédasticité ne sont pas respectées. 
\newline
\newline
On s'est basé sur la documentation du package lmerTest \cite{kuznetsovaLmerTestPackageTests2017} pour calculer les formules explicites de l'approximation dans notre cadre et ensuite les implémenter et voir si cela améliore la fiabilité de la statistique de test.
A partir de \ref{eq:eq2err} on rappelle les valeurs suivantes:
\[
 Y \sim \mathcal{N}_n(X\beta, \sigma^2_{phy}K + \sigma^2_{err}I_n) \text{, }\theta=(\sigma^2_{phy}, \sigma^2_{err}) \text{ et } Var_\theta(Y) = V(\theta) = \sigma^2_{phy}K + \sigma^2_{err}I_n 
\]
De là on obtient:
\begin{equation}
    C(\theta) = (Cov(\beta_i , \beta_j))_{i,j} = (X^TV(\theta)^{-1}X)^{-1} = (X^T(\sigma^2_{phy}K + \sigma^2_{err}I_n)^{-1}X)^{-1}
\end{equation}

Toujours en suivant la documentation \cite{kuznetsovaLmerTestPackageTests2017} on part de l'expression pour les degrés de liberté $df$ et de l'approximation. Ce qui nous donne :
\begin{equation}
    df = \frac{2(l^T\hat{C}l)^2}{[Var(l^T\hat{C}l)]}=\frac{2(f(\hat{\theta}))^2}{[Var(f(\hat{\theta}))]}\approx \frac{2(f(\hat{\theta}))^2}{[\nabla f(\hat{\theta})]^T A[\nabla f(\hat{\theta})]}
\end{equation} 
\[\text{où} \quad \hat{C} = C(\hat\theta) \quad \text{et} \quad f(\theta) = l^TC(\theta)l\]
A partir de cette expression, on calcule $\nabla f(\theta)$ qu'on appliquera en $\hat{\theta}$ et $A$ la matrice de variance-covariance de $\hat{\theta}=(\hat{\sigma}^2_{phy}, \hat{\sigma}^2_{err})$ 

\begin{proof}[Calcul du gradient]
Nous voulons calculer les dérivées partielles $\partial_{\sigma^2_{phy}}f(\theta)$ et $\partial_{\sigma^2_{err}}f(\theta)$. Pour les premières étapes de calculs, on écrira seulement $\partial$ sans distinction car ce sont les mêmes expressions pour les 2 dérivées. 
On utilisera dans la suite les formules de \cite{petersenMatrixCookbook2012} pour les dérivées de matrice
\[
\partial f(\theta)=l^T\partial C(\theta)l
\]
\[
\partial C(\theta)=\partial (X^TV(\theta)^{-1}X)^{-1} = -C(\theta) \partial (X^TV(\theta)^{-1}X)C(\theta)
\]

\[
    \partial (X^TV(\theta)^{-1}X) = \partial (X^TV(\theta)^{-1})X + \cancel{X^TV(\theta)^{-1}\partial(X)} \quad (\partial_{\sigma^2_{phy}}(X)\text{ et } \partial_{\sigma^2_{err}}(X) \text{ sont nulles})
\]
\[\partial (X^TV(\theta)^{-1}) = \partial(X^T)V(\theta)^{-1} + X^T\partial(V(\theta)^{-1}) = \cancel{\partial(X)^TV(\theta)^{-1}} + X^T\partial(V(\theta)^{-1})
\]
\[\partial (V(\theta)^{-1}) = -V(\theta)^{-1}\partial(V(\theta))V(\theta)^{-1}
\]
\[\partial (V(\theta)) = \partial(\sigma^2_{phy}K + \sigma^2_{err}I_n)
\]
Ce qui donne :
\[\partial_{\sigma^2_{phy}}(V(\theta)) = K, \quad \text{et} \quad \partial_{\sigma^2_{err}}(V(\theta)) = I_n
\]
De là en remettant les formules explicite les unes dans les autres, on obtient :
\[[\nabla f(\hat{\theta})] = \begin{bmatrix} \partial_{\sigma^2_{phy}}f(\hat{\theta}) \\ \partial_{\sigma^2_{err}}f(\hat{\theta}) \end{bmatrix}=\begin{bmatrix} l^TC(\hat{\theta})X^TV(\hat{\theta})^{-1}KV(\hat{\theta})^{-1}XC(\hat{\theta})l \\ l^TC(\hat{\theta})X^TV(\hat{\theta})^{-1}I_nV(\hat{\theta})^{-1}XC(\hat{\theta})l\end{bmatrix}
\]
\end{proof}

\begin{proof}[Calcul de A]
    A est la matrice variance-covariance de $\hat{\theta}$, c'est à dire l'inverse de la Hessienne $H$ de la vraissemblance de $\hat{\theta}$: $A=H^{-1}$
    Dans ce cadre on peut obtenir une formule explicite de la Hessienne, même si dans la plupart des cas il est plus simple d'estimer cette matrice par des méthodes numériques.
    On va d'abord calculer la log-vraissemblance du vecteur Y défini précédemment:
\begin{align*}
    \mathcal{L} (\bf{Y}, \theta)&= \log (\frac{1}{(2\pi)^{n/2}|V(\theta)|^{1/2}} \exp\left( -\frac{1}{2}(Y - X\beta)^T V(\theta)^{-1} (Y - X\beta) \right)) \\
    &= - \frac{n}{2} \log(2\pi) -\frac{1}{2} \log(|V(\theta)|) - \frac{1}{2}(Y - X\beta)^T V(\theta)^{-1} (Y - X\beta) \\
\end{align*}
On calcule les dérivées premières de la log-vraissemblance
\begin{align*}
    \partial_{\sigma^2_{phy}} \mathcal{L}  &= -\frac{1}{2} \partial_{\sigma^2_{phy}}(\log(|V(\theta)|)) - \frac{1}{2} \partial_{\sigma^2_{phy}}((Y - X\beta)^T V(\theta)^{-1} (Y - X\beta))\\
    &= -\frac{1}{2} Tr(V(\theta)^{-1}\partial_{\sigma^2_{phy}}(V(\theta))) - \frac{1}{2} (Y - X\beta)^T \partial_{\sigma^2_{phy}}(V(\theta)^{-1})(Y - X\beta)\\
    &= -\frac{1}{2} Tr(V(\theta)^{-1}K) + \frac{1}{2} (Y - X\beta)^T V(\theta)^{-1} K V(\theta)^{-1}(Y - X\beta)\\
\end{align*}
\begin{align*}
    \partial_{\sigma^2_{err}} \mathcal{L}  &= -\frac{1}{2} \partial_{\sigma^2_{err}}(\log(|V(\theta)|)) - \frac{1}{2} \partial_{\sigma^2_{err}}((Y - X\beta)^T V(\theta)^{-1} (Y - X\beta))\\
    &= -\frac{1}{2} Tr(V(\theta)^{-1}\partial_{\sigma^2_{err}}(V(\theta))) - \frac{1}{2} (Y - X\beta)^T \partial_{\sigma^2_{err}}(V(\theta)^{-1})(Y - X\beta)\\
    &= -\frac{1}{2} Tr(V(\theta)^{-1}I_n) + \frac{1}{2} (Y - X\beta)^T V(\theta)^{-1} I_n V(\theta)^{-1}(Y - X\beta)\\
\end{align*}
Puis les dérivées secondes:
\begin{align*}
    \bf{\partial_{\sigma^2_{phy}\sigma^2_{phy}}\mathcal{L}} &= -\frac{1}{2} \partial_{\sigma^2_{phy}\sigma^2_{phy}} (Tr(V(\theta)^{-1}K)) + \frac{1}{2} \partial_{\sigma^2_{phy}\sigma^2_{phy}} \left( (Y - X\beta)^T V(\theta)^{-1} K V(\theta)^{-1}(Y - X\beta) \right)\\
    &= -\frac{1}{2} Tr(\partial_{\sigma^2_{phy}\sigma^2_{phy}} (V(\theta)^{-1})K) + \frac{1}{2}  (Y - X\beta)^T \partial_{\sigma^2_{phy}\sigma^2_{phy}}(V(\theta)^{-1} K V(\theta)^{-1})(Y - X\beta) \\
    &= \frac{1}{2} Tr(V(\theta)^{-1}KV(\theta)^{-1}K) -  (Y - X\beta)^T V(\theta)^{-1}KV(\theta)^{-1} K V(\theta)^{-1}(Y - X\beta) \\
\end{align*}
\[\text{car} \quad \partial ((Y - X\beta)^T V(\theta)^{-1} K V(\theta)^{-1}(Y - X\beta)) = (Y - X\beta)^T \partial ( V(\theta)^{-1} K V(\theta)^{-1})(Y - X\beta)\]
\[\text{et} \quad \partial \left( V(\theta)^{-1} K V(\theta)^{-1} \right) = -V(\theta)^{-1} \partial V(\theta) V(\theta)^{-1} K V(\theta)^{-1} - V(\theta)^{-1} K V(\theta)^{-1} \partial V(\theta) V(\theta)^{-1}\]
\[\text{ce qui donne} \quad\partial_{\sigma^2_{phy}\sigma^2_{phy}} \left( V(\theta)^{-1} K V(\theta)^{-1} \right) = -2V(\theta)^{-1} K V(\theta)^{-1} K V(\theta)^{-1}\]
\begin{align*}
    &{\bf\partial_{\sigma^2_{err}\sigma^2_{phylo}}\mathcal{L}} = \bf{\partial_{\sigma^2_{phy}\sigma^2_{err}}\mathcal{L}} \\
    &= -\frac{1}{2} Tr(\partial_{\sigma^2_{phy}\sigma^2_{err}} (V(\theta)^{-1})K) + \frac{1}{2}  (Y - X\beta)^T \partial_{\sigma^2_{phy}\sigma^2_{err}}(V(\theta)^{-1} K V(\theta)^{-1})(Y - X\beta) \\
    &= \frac{1}{2} Tr(V(\theta)^{-1}I_nV(\theta)^{-1}K) - \frac{1}{2} (Y - X\beta)^T (V(\theta)^{-1}V(\theta)^{-1}KV(\theta)^{-1} + V(\theta)^{-1}KV(\theta)^{-1}V(\theta)^{-1})(Y - X\beta) \\
\end{align*}
\[\text{car} \quad \partial_{\sigma^2_{phy}\sigma^2_{err}} \left( V(\theta)^{-1} K V(\theta)^{-1} \right) = -(V(\theta)^{-1}V(\theta)^{-1}KV(\theta)^{-1} + V(\theta)^{-1}KV(\theta)^{-1}V(\theta)^{-1})\]
\begin{align*}
    \bf{\partial_{\sigma^2_{err}\sigma^2_{err}} \mathcal{L}}  &= -\frac{1}{2} \partial_{\sigma^2_{err}\sigma^2_{err}} (Tr(V(\theta)^{-1})) + \frac{1}{2} \partial_{\sigma^2_{err}\sigma^2_{err}} \left( (Y - X\beta)^T V(\theta)^{-1} V(\theta)^{-1}(Y - X\beta) \right)\\
    &=\frac{1}{2}Tr(V(\theta)^{-1}V(\theta)^{-1}) - (Y - X\beta)^T V(\theta)^{-1}V(\theta)^{-1}V(\theta)^{-1}(Y - X\beta)
\end{align*}

De là on obtient la Hessienne $\begin{pmatrix}
    \partial_{\sigma^2_{phy}\sigma^2_{phy}}\mathcal{L} & \partial_{\sigma^2_{phy}\sigma^2_{err}}\mathcal{L} \\
    \partial_{\sigma^2_{err}\sigma^2_{phy}}\mathcal{L} & \partial_{\sigma^2_{err}\sigma^2_{err}}\mathcal{L} \\
\end{pmatrix}$ puis A en l'inversant, ce qui peut se faire par des méthodes numériques.

\end{proof}
TODO: trouver erreur de signe 
% \[\]
% Supposons que nous avons une expression $x^2 - 2x + \cancel{3} - 3$. Comme la partie $\cancel{3}$ est nulle, nous pouvons la barrer.

% TODO REML voir sujet d'exam corrigée
% Quand estimateur classique on divise par n-p au lieu de diviser par n donc on 
% fait sans le dire un REML.
% Au lieu de maximiser la vraisemblance on maximise la vraisemblance restreinte
% Gaussien : effet fixe les betas, pour estimer al variance on projette sur 
% l'orthogonal et on estime sigma sur l'orthogonal.

% Si bayésien on met un prior impropre sur les betas et on intègre apr rapport aux 
\subsection{REML}
REML, ou Maximum de Vraisemblance Restreint (Restricted Maximum Likelihood en anglais), est une méthode statistique utilisée dans l'estimation des paramètres de modèles linéaires mixtes (ou modèles à effets mixtes) et dans l'analyse de la variance (ANOVA). Il s'agit d'une approche alternative à la méthode de maximum de vraisemblance (ML) standard, notamment lorsque l'on travaille avec des modèles à effets aléatoires.
\newline
\newline
TODO: formule pour montrer la différence ? 
TODO: Pourquoi l'utiliser pour Satterthwaite ? 
\section{Méthodologie}
\label{chap:metho}
lrt 
ANOVA normale 
VANILLA = ANOVA phylo sans correction des degrés de liberté $df1 = K - 1, df2 = n-K$
ANOVA phylo (avec REML)

test sur arbre quelconque
puis sur arbre avec petites branches ? 

% Ou faire une partie à part entière avec 
% 1) ANOVA vs ANOVA phylo sans correction des degrés de liberté
%  b) avec une sous partie sur le REML

% 2) ANOVA phylo avec approximation de SAtterthwaite 
%  a) prez
%  a`) simulation et résultats 
%  b) instabilités numériques -> correction avec la Hessienne ? 
%  c) La hessienne analytique ? A voir si besoin d'une partie supplémentaire
 

3 parties :
- théo
- méthodo par simu
- appli aux données réelles



\subsection{Simulations}
% On importe le fichier

<<simulations-methodes, child='Rnw/simulations-methodes.Rnw'>>=
@

\section{Données}
\label{sec:data}
% Présentation des données utilisées.
<<donnees-reelles, child='Rnw/donnees-reelles.Rnw'>>=
@

Revenir sur explication de gènes différentiellement exprimées etc.

Applications aux données réelles de Chen mais ne pas perdre de temps à expliquer en détails EVEmodel (dire que c'est State of the art).

\section{Résultats}
\label{sec:results}
% Présentation des résultats obtenus.

% Présenter EVEmodel et son usage


\section{Discussion et conclusion}
\label{sec:discuss_conclusion}
% Analyse critique des résultats, limites, perspectives.

Intro

Application/Résultats: décrire les données, vite fait normalisation avec vrai aebre, on ne connait pas 
Discussion/COnclusion ? Interprétation des résultats sinon la mettre dans les 
f-cicd: CI/CD to build Latex PDF ...
CI/CD to build Latex pdf and create a release in with GitHub Actions. The workflow triggers on push to the repository. Integrates with Overleaf.
% Bibliographie
\printbibliography
\nocite{*}

% TODO Ici éventuellement une partie annexe discussion de l'impact des tailles d'abres
\appendix
\section{Application aux données réelles}

Comme nous l'avons remarqué dans la section~\ref{sec:data} l'application de la
méthode EVEmodel a produit des valeurs manquantes pour les gènes présentés dans
le tableau suivant.

\begin{table}[H]
    \centering
    <<'table_nas'>>=
    knitr::kable(evegenesNA, col.names = "Gènes ayant produits des NA", 
        align = "c", booktabs = TRUE, format = "latex", escape = TRUE)
    @
    \caption{Table des gènes pour lesquels la méthode \texttt{EVEmodel} a produit des NA}
    \label{tab:na-evemodel}
\end{table}

\section*{Code du projet}

Tout le code produit est disponible sur le dépôt GitHub suivant 
\url{https://github.com/Polarolouis/anova-phylogenetique-projet-msv/}.
Ce dépôt contient le code pour implémenter la méthode, faire les 
simulations et compiler le rapport.


Nous avons au maximum indiqué le code qui n'a pas été écrit par nous, la plupart
du temps dans les commentaires du code.

\end{document}