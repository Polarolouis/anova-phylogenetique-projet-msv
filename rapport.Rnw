\documentclass[a4paper, 12pt]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{geometry}

%Images
\usepackage{graphicx}
\graphicspath{{img/}}
\usepackage{float}
\usepackage{subcaption} %  for subfigures environments 

% Booktabs
\usepackage{booktabs}

% Citation
\usepackage{csquotes}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage{cancel}

\usepackage[style=authoryear-comp,backend=biber]{biblatex}
%== use and define color ==%
\AtEveryCite{\color{blue}}
\addbibresource{references.bib}

% Configurations
\geometry{a4paper, margin=2.5cm}
\graphicspath{ {img/} }

% Macros utiles
\newcommand{\Normal}{\mathcal{N}}


% Titre du document
\title{Rapport de Projet : ANOVA Phylogénétique}
\author{Alizée Geffroy \and Louis Lacoste}
\date{\today}

\begin{document}

\maketitle

<<'init', include=FALSE>>=
    knitr::opts_chunk$set(echo = FALSE)
    require("knitr", quietly = TRUE)
    options(knitr.table.format = "latex")
@

<<'libraries', include=FALSE>>=
# "phytools", "phylotools"
necessary_packages <- c("ape", "here")
if (any(!(necessary_packages %in% installed.packages()))) {
    install.packages(necessary_packages)
}

# require(phytools)
# require(phylotools)
require(ape)
require(here)


source(here("R","utils.R"))
@

\newpage
\tableofcontents
\newpage

\section{Introduction}
\label{chap:intro}
% Introduction au projet, contexte, objectifs.
Ici contexte biologique, les données de \cite{gomez-mestrePhylogeneticAnalysesReveal2012}, les données de Paul et Mélina, etc.

Avec l'avènement des données massives de génomiques, transcriptomiques, protéomiques etc, il y a besoin de techniques statistiques robustes et passant à l'échelle permettant de mener à bien l'anal
Format des données : arbres phylogénétiques, données génétiques 
Arbres avec des petites branche: plusieurs individus par espèces avec chacun leurs données 
--> problème biologique 

Deux sujets différents écologie et transcriptomique mais une même méthode.

Pour données \cite{chenQuantitativeFrameworkCharacterizing2019} la figure~\ref{fig:arbre-chen2019} présente l'arbre phylogénétique :

\begin{figure}[!h]
    \centering
<<'plot-arbre-chen'>>=
    tree <- read.tree(here("R","chen2019.tree"))
    # Normalising tree edge length
    taille_tree <- diag(vcv(tree))[1]
    tree$edge.length <- tree$edge.length / taille_tree

    phytools::plotTree(tree, ftype="i")
@
    \caption{Arbre phylogénétique de \cite{chenQuantitativeFrameworkCharacterizing2019}}
    \label{fig:arbre-chen2019}
\end{figure}


Transition, c'est pourquoi on va tester la méthode d'ANOVA phylogénétique avec cette forme de données. 
But ? Etudier cette méthode et les résultats 

Un gène, comparer les moyennes d'expression d'un gène 
On connait les groupes
exemple individus malade/sain

Comparaison non pas sur individus malades/pas malades mais sur espèces différentes.
Pas possible de supposer iid, existe relations entre les individus et les groupes que l'on compare donc besoin de les prendre en compte.

Modele mixte la matrice des temps de divergences, BM simple sans erreurs, avec erreur (ajustement du ratio) avec OU...

\section{Méthodes}
\label{sec:methode}
% Revue de la littérature sur l'ANOVA phylogénétique.
Ici les rappels sur l'ANOVA, l'explication de l'ANOVA phylogénétique. La démonstration des limites de l'ANOVA phylogénétique par des simulations
Méthode: la partie maths anova, anova phylo, satterthwaite, 

\subsection{L'ANOVA}

L'ANOVA est un cas classique du modèle linéaire, nous utilisons ici les notations et le formalisme de \cite{belModeleLineaireSes}.

Le principe de l'ANOVA est d'expliciter le lien entre une variable quantitative et une ou plusieurs variables qualitatives.

La forme usuelle de l'ANOVA à 1 facteur est la suivante :

\begin{align}
Y_{ik} = \mu_i + E_{ik}, & &i = 1,\dots I, k = 1,\dots n_i, E_{ik} \sim \Normal (0, \sigma^2)
\end{align}

où dans cette équation, reprise du livre \parencite{belModeleLineaireSes}, $i$ représente le niveau du facteur et $k$ indique le numéro de l'observation dans ce niveau. $I$ est le nombre total de niveaux du facteur, $n_i$ le nombre d'observation du niveau $i$. 

L'ANOVA se généralise à deux facteurs, plus facilement compréhensible avec cette forme, non identifiable :
\begin{align}
Y_{ijk} = \mu + \alpha_i + \beta_j + E_{ijk}, & &i = 1,\dots I, j = 1,\dots J, k = 1,\dots n_ij, E_{ijk} \sim \Normal (0, \sigma^2)
\end{align}

où $\mu$ représente un effet moyen de la population (\emph{intercept}), $\alpha_i$ l'effet du premier facteur de niveau $i$, $\beta_j$ l'effet du second facteur de niveau $j$.

Les paramètres de l'ANOVA sont estimables, grâce par exemple à la méthode du maximum de vraisemblance et ont des formules bien connues.

% ICI LES FORMULES

% LIMITES de l'ANOVA classique sur les données phylo

\subsection{L'ANOVA phylogénétique}

parler du BM ? 
% Besoin de le dire qu'on fait une régression linéaire matrice structurée, 
% figure avec le Brownien sur l'arbre à reprendre dans le chapitre de livre
PUis de la matrice V ou K qui donne la structure phylogénétique 

Etre assez concis sur l'histoire de la projection et le modèle et les différences avec l'ANOVA. 


% TODO Définir les tests stats
\subsection{Approximation de Satterthwaite}

Pourquoi vouloir l'utiliser ? Réduire nbre de degrés de liberté utilisés dans la stat de test. 
Le but est d'approximé le nbre de degré de Liberté. 
On se basera sur la documentation du package lmer \cite{kuznetsovaLmerTestPackageTests2017} pour calculer les formules explicites de l'approximation  dans notre cadre et ensuite implémenter l'implémenter.. 
\begin{equation}
    Y = X\beta + u + \epsilon 
\end{equation} 
\[
\text{où} \quad \mathbf{Y} = \begin{bmatrix} Y_1 \\ Y_2 \\ \vdots \\ Y_n \end{bmatrix}, \mathbf{\beta} = \begin{bmatrix} \beta_1 \\ \beta_2  \end{bmatrix}\text{,} \quad u \sim \mathcal{N}_n(0, \sigma^2_{phy}K) \text{,} \quad \epsilon \sim \mathcal{N}_n(0, \sigma^2_{err}I_n)
\]
\newline
\[
 \text{Alors} \quad Y \sim \mathcal{N}_n(X\beta, \sigma^2_{phy}K + \sigma^2_{err}I_n) \quad \text{et} \quad Var_\theta(Y) = V(\theta) = \sigma^2_{phy}K + \sigma^2_{err}I_n
\]
De là on obtient:
\begin{equation}
    C(\theta) = (Cov(\beta_i , \beta_j))_{i,j} = (X^TV(\theta)^{-1}X)^{-1} = (X^T(\sigma^2_{phy}K + \sigma^2_{err}I_n)^{-1}X)^{-1}
\end{equation}

Toujours en suivant la documentation \cite{kuznetsovaLmerTestPackageTests2017} on part de l'expression pour les degrés de liberté $df$ et de l'approximation. Ce qui nous donne :
\begin{equation}
    df = \frac{2(l^T\hat{C}l)^2}{[Var(l^T\hat{C}l)]}=\frac{2(f(\hat{\theta}))^2}{[Var(f(\hat{\theta}))]}\approx \frac{2(f(\hat{\theta}))^2}{[\nabla f(\hat{\theta})]^T A[\nabla f(\hat{\theta})]}
\end{equation} 
\[\text{où} \quad \hat{C} = C(\hat\theta) \quad \text{et} \quad f(\theta) = l^TC(\theta)l\]
A partir de cette expression, on calcule $\nabla f(\theta)$ qu'on appliquera en $\hat{\theta}$ et $A$ la matrice de variance-covariance de $\hat{\theta}=(\hat{\sigma}^2_{phy}, \hat{\sigma}^2_{err})$ 

\begin{proof}[Calcul du gradient]
Nous voulons calculer les dérivées partielles $\partial_{\sigma^2_{phy}}f(\theta)$ et $\partial_{\sigma^2_{err}}f(\theta)$. Pour les premières étapes de calculs, on écrira seulement $\partial$ sans distinction car ce sont les mêmes expressions pour les 2 dérivées. 
On utilisera dans la suite les formules de \cite{petersenMatrixCookbook2012} pour les dérivées de matrice
\[
\partial f(\theta)=l^T\partial C(\theta)l
\]
\[
\partial C(\theta)=\partial (X^TV(\theta)^{-1}X)^{-1} = -C(\theta) \partial (X^TV(\theta)^{-1}X)C(\theta)
\]

\[
    \partial (X^TV(\theta)^{-1}X) = \partial (X^TV(\theta)^{-1})X + \cancel{X^TV(\theta)^{-1}\partial(X)} \quad (\partial_{\sigma^2_{phy}}(X)\text{ et } \partial_{\sigma^2_{err}}(X) \text{ sont nulles})
\]
\[\partial (X^TV(\theta)^{-1}) = \partial(X^T)V(\theta)^{-1} + X^T\partial(V(\theta)^{-1}) = \cancel{\partial(X)^TV(\theta)^{-1}} + X^T\partial(V(\theta)^{-1})
\]
\[\partial (V(\theta)^{-1}) = -V(\theta)^{-1}\partial(V(\theta))V(\theta)^{-1}
\]
\[\partial (V(\theta)) = \partial(\sigma^2_{phy}K + \sigma^2_{err}I_n)
\]
Ce qui donne :
\[\partial_{\sigma^2_{phy}}(V(\theta)) = K, \quad \text{et} \quad \partial_{\sigma^2_{err}}(V(\theta)) = I_n
\]
De là en remettant les formules explicite les unes dans les autres, on obtient :
\[[\nabla f(\hat{\theta})] = \begin{bmatrix} \partial_{\sigma^2_{phy}}f(\hat{\theta}) \\ \partial_{\sigma^2_{err}}f(\hat{\theta}) \end{bmatrix}=\begin{bmatrix} l^TC(\hat{\theta})X^TV(\hat{\theta})^{-1}KV(\hat{\theta})^{-1}XC(\hat{\theta})l \\ l^TC(\hat{\theta})X^TV(\hat{\theta})^{-1}I_nV(\hat{\theta})^{-1}XC(\hat{\theta})l\end{bmatrix}
\]
\end{proof}

\begin{proof}[Calcul de A]
    A est la matrice variance-covariance de $\hat{\theta}$, c'est à dire l'inverse de la Hessienne $H$ de la vraissemblance de $\hat{\theta}$.
    \[A=H^{-1}\]
    Dans ce cadre on peut obtenir une formule explicite de la Hessienne, même si dans la plupart des cas il est plus simple d'estimer cette matrice par des méthodes numériques.
    On va d'abord calculer la log-vraissemblance du vecteur Y défini précédemment:
\begin{align*}
    \mathcal{L} (\bf{Y}, \theta)&= \log (\frac{1}{(2\pi)^{n/2}|V(\theta)|^{1/2}} \exp\left( -\frac{1}{2}(Y - X\beta)^T V(\theta)^{-1} (Y - X\beta) \right)) \\
    &= - \frac{n}{2} \log(2\pi) -\frac{1}{2} \log(|V(\theta)|) - \frac{1}{2}(Y - X\beta)^T V(\theta)^{-1} (Y - X\beta) \\
\end{align*}
On calcule les dérivées premières de la log-vraissemblance
\begin{align*}
    \partial_{\sigma^2_{phy}} \mathcal{L}  &= -\frac{1}{2} \partial_{\sigma^2_{phy}}(\log(|V(\theta)|)) - \frac{1}{2} \partial_{\sigma^2_{phy}}((Y - X\beta)^T V(\theta)^{-1} (Y - X\beta))\\
    &= -\frac{1}{2} \frac{K}{|V(\theta)|} - \frac{1}{2} (Y - X\beta)^T V(\theta)^{-1} K V(\theta)^{-1}(Y - X\beta)\\
\end{align*}
\begin{align*}
    \partial_{\sigma^2_{err}} \mathcal{L}  &= -\frac{1}{2} \partial_{\sigma^2_{err}}(\log(|V(\theta)|)) - \frac{1}{2} \partial_{\sigma^2_{err}}((Y - X\beta)^T V(\theta)^{-1} (Y - X\beta))\\
    &= -\frac{1}{2} \frac{I_n}{|V(\theta)|} - \frac{1}{2} (Y - X\beta)^T V(\theta)^{-1} I_n V(\theta)^{-1}(Y - X\beta)\\
\end{align*}
Puis les dérivées secondes:
\begin{align*}
    \bf{\partial_{\sigma^2_{phy}\sigma^2_{phy}}\mathcal{L}} &= -\frac{1}{2} \partial_{\sigma^2_{phy}\sigma^2_{phy}} \left( \frac{K}{|V(\theta)|} \right) - \frac{1}{2} \partial_{\sigma^2_{phy}\sigma^2_{phy}} \left( (Y - X\beta)^T V(\theta)^{-1} K V(\theta)^{-1}(Y - X\beta) \right)\\
    &= \frac{1}{2}  \frac{K^2}{V(\theta)^2} + (Y - X\beta)^T V(\theta)^{-1} K V(\theta)^{-1}KV(\theta)^{-1} (Y - X\beta)\\
\end{align*}
car \[\partial \left( (Y - X\beta)^T V(\theta)^{-1} K V(\theta)^{-1}(Y - X\beta) \right) = (Y - X\beta)^T \partial \left( V(\theta)^{-1} K V(\theta)^{-1} \right)(Y - X\beta)\]
et \[\partial \left( V(\theta)^{-1} K V(\theta)^{-1} \right) = -V(\theta)^{-1} \partial V(\theta) V(\theta)^{-1} K V(\theta)^{-1} - V(\theta)^{-1} K V(\theta)^{-1} \partial V(\theta) V(\theta)^{-1}\]
ce qui donne \[\partial_{\sigma^2_{phy}\sigma^2_{phy}} \left( V(\theta)^{-1} K V(\theta)^{-1} \right) = -2V(\theta)^{-1} K V(\theta)^{-1} K V(\theta)^{-1}\]
\begin{align*}
    &{\bf\partial_{\sigma^2_{err}\sigma^2_{phylo}}\mathcal{L}} = \bf{\partial_{\sigma^2_{phy}\sigma^2_{err}}\mathcal{L}} \\
    &= -\frac{1}{2} \partial_{\sigma^2_{phy}\sigma^2_{err}} \left( \frac{K}{|V(\theta)|} \right) - \frac{1}{2} \partial_{\sigma^2_{phy}\sigma^2_{err}} \left( (Y - X\beta)^T V(\theta)^{-1} K V(\theta)^{-1}(Y - X\beta) \right)\\
    &= \frac{1}{2}  \frac{K}{V(\theta)^2} + \frac{1}{2}(Y - X\beta)^T (V(\theta)^{-1}V(\theta)^{-1}KV(\theta)^{-1} + V(\theta)^{-1}KV(\theta)^{-1}V(\theta)^{-1}) (Y - X\beta)\\
\end{align*}
car \[\partial_{\sigma^2_{phy}\sigma^2_{err}} \left( V(\theta)^{-1} K V(\theta)^{-1} \right) = -V(\theta)^{-1}V(\theta)^{-1}KV(\theta)^{-1} + V(\theta)^{-1}KV(\theta)^{-1}V(\theta)^{-1}\]
\begin{align*}
    \bf{\partial_{\sigma^2_{err}\sigma^2_{err}} \mathcal{L}}  &= -\frac{1}{2} \partial_{\sigma^2_{err}\sigma^2_{err}} \left( \frac{I_n}{|V(\theta)|} \right) - \frac{1}{2} \partial_{\sigma^2_{err}\sigma^2_{err}} \left( (Y - X\beta)^T V(\theta)^{-1} V(\theta)^{-1}(Y - X\beta) \right)\\
    &=\frac{1}{2}\frac{I_n}{V(\theta)^2} + (Y - X\beta)^T V(\theta)^{-1}V(\theta)^{-1}V(\theta)^{-1}(Y - X\beta)
\end{align*}

\end{proof}
\[\]
% Supposons que nous avons une expression $x^2 - 2x + \cancel{3} - 3$. Comme la partie $\cancel{3}$ est nulle, nous pouvons la barrer.

% TODO REML voir sujet d'exam corrigée
% Quand estimateur classique on divise par n-p au lieu de diviser par n donc on 
% fait sans le dire un REML.
% Au lieu de maximiser la vraisemblance on maximise la vraisemblance restreinte
% Gaussien : effet fixe les betas, pour estimer al variance on projette sur 
% l'orthogonal et on estime sigma sur l'orthogonal.

% Si bayésien on met un prior impropre sur les betas et on intègre apr rapport aux 

\section{Méthodologie}
\label{chap:metho}
lrt 
ANOVA normale 
VANILLA = ANOVA phylo sans correction des degrés de liberté $df1 = K - 1, df2 = n-K$
ANOVA phylo (avec REML)

test sur arbre quelconque
puis sur arbre avec petites branches ? 

% Ou faire une partie à part entière avec 
% 1) ANOVA vs ANOVA phylo sans correction des degrés de liberté
%  b) avec une sous partie sur le REML

% 2) ANOVA phylo avec approximation de SAtterthwaite 
%  a) prez
%  a`) simulation et résultats 
%  b) instabilités numériques -> correction avec la Hessienne ? 
%  c) La hessienne analytique ? A voir si besoin d'une partie supplémentaire
 

3 parties :
- théo
- méthodo par simu
- appli aux données réelles



\subsection{Simulations}
% On importe le fichier

<<simulations-methodes, child='Rnw/simulations-methodes.Rnw'>>=
@

\section{Données}
\label{sec:data}
% Présentation des données utilisées.
<<donnees-reelles, child='Rnw/donnees-reelles.Rnw'>>=
@

Revenir sur explication de gènes différentiellement exprimées etc.

Applications aux données réelles de Chen mais ne pas perdre de temps à expliquer en détails EVEmodel (dire que c'est State of the art).

\section{Résultats}
\label{sec:results}
% Présentation des résultats obtenus.

% Présenter EVEmodel et son usage


\section{Discussion et conclusion}
\label{sec:discuss_conclusion}
% Analyse critique des résultats, limites, perspectives.

Intro

Application/Résultats: décrire les données, vite fait normalisation avec vrai aebre, on ne connait pas 
Discussion/COnclusion ? Interprétation des résultats sinon la mettre dans les 
f-cicd: CI/CD to build Latex PDF ...
CI/CD to build Latex pdf and create a release in with GitHub Actions. The workflow triggers on push to the repository. Integrates with Overleaf.
% Bibliographie
\printbibliography
\nocite{*}

% TODO Ici éventuellement une partie annexe discussion de l'impact des tailles d'abres
\appendix
\section{Application aux données réelles}

Comme nous l'avons remarqué dans la section~\ref{sec:data} l'application de la
méthode EVEmodel a produit des valeurs manquantes pour les gènes présentés dans
le tableau suivant.

\begin{table}[H]
    \centering
    <<'table_nas'>>=
    knitr::kable(evegenesNA, col.names = "Gènes ayant produits des NA", 
        align = "c", booktabs = TRUE, format = "latex", escape = TRUE)
    @
    \caption{Table des gènes pour lesquels la méthode \texttt{EVEmodel} a produit des NA}
    \label{tab:na-evemodel}
\end{table}

\section*{Code du projet}

Tout le code produit est disponible sur le dépôt GitHub suivant 
\url{https://github.com/Polarolouis/anova-phylogenetique-projet-msv/}.
Ce dépôt contient le code pour implémenter la méthode, faire les 
simulations et compiler le rapport.


Nous avons au maximum indiqué le code qui n'a pas été écrit par nous, la plupart
du temps dans les commentaires du code.

\end{document}